{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Addding Memory into the chat bot\n",
    "\n",
    "- why this is importent.\n",
    "    1. Our chatbot does not have the access of previous context thats why this is importent.\n",
    "    2. With the previous context it limit the ability of multi-turn conversation.\n",
    "\n",
    "- How Can we acheive this using `checkpointing`.\n",
    "    1. We can provide the memory using the compilation of the graph.\n",
    "    2. When calling the graph Langgraph automatically save the state after each step.\n",
    "    3. When we call the graph using same `thread_id` the graph loads its saved state. allowing chatbot to pick up from there.\n",
    "    4. Using checkpointing we can resume and complex state at anytime,\n",
    "\n",
    "To Created create a Memory Saver checkpointer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Notice`: We are using checkpoint. This is conveniet for tutorial. In Production Application you would like to change this to use `mongo` , `postgres`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage,AIMessage,SystemMessage\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"You are a professional communicator that gives responses in a professional way.\"),\n",
    "    MessagesPlaceholder(\"user_input\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T07:07:44.997870Z",
     "start_time": "2025-02-19T07:07:44.994225Z"
    }
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T07:07:44.440528Z",
     "start_time": "2025-02-19T07:07:43.734161Z"
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "\n",
    "tools = [tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1fc203f1400>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END \n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages:Annotated[list,add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state:State):\n",
    "    if messages := state.get(\"messages\",{}):        \n",
    "        response = llm_with_tools.invoke(messages)\n",
    "        return {\"messages\": [response]}\n",
    "    else:\n",
    "        raise ValueError(\"Messages is not found\")\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1fc203f1400>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "class BasicToolNode:\n",
    "    def __init__(self,tools:list) -> None:\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "\n",
    "    def __call__(self, input: dict) -> dict:\n",
    "        if messages := input.get(\"messages\",[]):\n",
    "            message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"No Message found in the input\")\n",
    "\n",
    "        outputs = []\n",
    "\n",
    "        for tool_call in message.tool_calls:\n",
    "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n",
    "            \n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content = json.dumps(tool_result),\n",
    "                    name = tool_call[\"name\"],\n",
    "                    tool_call_id = tool_call[\"id\"]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        return {\"messages\" : outputs}\n",
    "\n",
    "tool_node = BasicToolNode(tools = tools)\n",
    "\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_tools(state: State):\n",
    "    \"\"\"\n",
    "        Use in the conditional_edge to route to the ToolNode if the last message\n",
    "        has tool calls. Otherwise, route to the end.\n",
    "    \"\"\"\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    elif messages := state.get(\"messages\",[]):\n",
    "        ai_message = messages[-1]\n",
    "    else:\n",
    "        raise ValueError(f\"No message found in input state to tool_edge: {state}\")\n",
    "    \n",
    "    if hasattr(ai_message,\"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"\n",
    "    \n",
    "    return END\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    route_tools,\n",
    "    {\"tools\":\"tools\",END:END}\n",
    ")\n",
    "\n",
    "# EDGES DEFINE THE ORDER FOR DECISIONS --> LIKE BELOW \n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what is the capital of india.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The capital of India is New Delhi.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "whats its population.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (call_C4e8lGomuQ0BLF68AhWVBfvx)\n",
      " Call ID: call_C4e8lGomuQ0BLF68AhWVBfvx\n",
      "  Args:\n",
      "    query: population of New Delhi 2023\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://www.macrotrends.net/cities/21228/delhi/population\", \"content\": \"The metro area population of Delhi in 2023 was 32,941,000, a 2.73% increase from 2022. The metro area population of Delhi in 2022 was 32,066,000, a 2.84%\"}, {\"url\": \"https://worldpopulationreview.com/cities/india/delhi\", \"content\": \"Delhi, India Population 2024 Delhi, India Population 2024 Delhi's 2024 population is now estimated at 33,807,400. In 1950, the population of Delhi was 1,369,370. Delhi has grown by 866,100 in the last year, which represents a 2.63% annual change.These population estimates and projections come from the latest revision of the UN World Urbanization Prospects. Delhi is the fifth most populous city in the world and the largest city in India area-wise. Delhi has an estimated 2016 population of 18.6 million. Delhi has a rapidly growing population, which was near 16.7 million in 2011. Delhi Population Growth Delhi Population Data (Urban Area) | Delhi | 33,807,400 | 2.63% | India Census 2011 - Delhi - Delhi population census data 2011\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "As of 2023, the metropolitan area population of New Delhi is approximately 32,941,000, reflecting a 2.73% increase from the previous year. By 2024, the population is estimated to reach around 33,807,400. \n",
      "\n",
      "You can find more details about the population on [Macrotrends](https://www.macrotrends.net/cities/21228/delhi/population) and [World Population Review](https://worldpopulationreview.com/cities/india/delhi).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "config = {\"configurable\" : {\"thread_id\" : \"2\"}}\n",
    "\n",
    "def call_chat_bot(user_input:str):\n",
    "    # for events in graph.stream({\"messages\": user_input}):\n",
    "    #     for value in events.values():\n",
    "    #         if \"messages\" in value:\n",
    "    #             print(\"Assistant: \",value[\"messages\"][-1].content)\n",
    "\n",
    "    events = graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]},config,\n",
    "    stream_mode=\"values\",)\n",
    "    \n",
    "    for event in events:\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "\n",
    "    if user_input.lower() in [\"quit\", \"q\", \"exit\"]:\n",
    "        break\n",
    "    \n",
    "    call_chat_bot(user_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
