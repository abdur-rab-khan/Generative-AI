{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce93fec7",
   "metadata": {},
   "source": [
    "- Table of content\n",
    "  - [Loading a PDF's](#loading-a-pdfs)\n",
    "    - [Simple and fast text extraction](#simple-and-fast-text-extraction)\n",
    "      - [Vector search over PDF's](#vector-search-over-pdfs)\n",
    "    - [Layout analysis and extraction of text from images](#layout-analysis-and-extraction-of-text-from-images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c6ee68",
   "metadata": {},
   "source": [
    "# Loading a PDF's."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeff9e9",
   "metadata": {},
   "source": [
    "- PDF's are typically represent via text boxes. that may also contain images.\n",
    "- A PDF Parser are combination of following:\n",
    "  1.  Convert text box in to lines, paragraphs, and other structure using heuristics or ML inference.\n",
    "  2. Run OCR (an electronic device that scan handwritten, printed text into encoded text) on the image to detect text.\n",
    "  3. Classify text as belonging paragraph, lists, tables other structure.\n",
    "  4. Structure text into table rows and columns, or key-value pairs.\n",
    "\n",
    "- **IMPORTANT TO NOTE**\n",
    "  - My modern LLM's supports multi-model data such as images.\n",
    "  - So we can you following approach instead of parsing PDF.\n",
    "    - We can pass the image of pdf page.\n",
    "    - Below we have example how to do tht.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f711c2",
   "metadata": {},
   "source": [
    "## Simple and fast text extraction.\n",
    "\n",
    "- It is very simple, If you want to extract the text content embedded in a PDF. \n",
    "- It only extract the text from the pdf, it will not parse text inside the image.\n",
    "- It return a list of [Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html) objects per -- one per page. Containing page text in the Document's **`page_content`** attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da0244f",
   "metadata": {},
   "source": [
    "- LangChain [document loaders](../document_loader.md) implements with `lazy_load`, for async variants `alazy_load`, which returns an iterators of Document objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e45c9695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"same_files/welcome.pdf\")\n",
    "\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb2f87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 MetaData\n",
      "{'producer': 'Adobe PDF Library 21.1.174', 'creator': 'Acrobat PDFMaker 21 for Word', 'creationdate': '2024-06-18T22:34:29+00:00', 'author': 'Adobe', 'comments': '', 'company': 'Adobe', 'keywords': '', 'moddate': '2024-06-24T08:31:18-07:00', 'sourcemodified': 'D:20240618223427', 'subject': '', 'title': 'Welcome to Adobe Acrobat', 'source': 'same_files/welcome.pdf', 'total_pages': 6, 'page': 0, 'page_label': '1'}\n",
      "Page 1 Content\n",
      "Welcome to  \n",
      "Adobe Acrobat \n",
      "Here are five tips to get real work  \n",
      "done from anywhere with Acrobat.  \n",
      "01 Work where you want \n",
      "02 Meet Acrobat AI Assistant \n",
      "03 Present perfect content \n",
      "04 Share files with others \n",
      "05 Get help from Adobe\n"
     ]
    }
   ],
   "source": [
    "print(f\"Page 1 MetaData\")\n",
    "print(f\"{pages[0].metadata}\")  # It also store the corresponding page numbers.\n",
    "print(\"Page 1 Content\")\n",
    "print(f\"{pages[0].page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62ad7f8",
   "metadata": {},
   "source": [
    "### Vector search over PDF's\n",
    "\n",
    "- Once we have loaded pdf's into LangChain [Document](../document_loader.md) object. we can index them (e.g a RAG application) in the usual way.\n",
    "- Below we use OpenAI embedding, although any LangChain embedding model will sufficient for indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8cbf1a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 4: 04 Share files with others \n",
      "Send and manage \n",
      " \n",
      "Now you can share files for \n",
      "viewing, commenting, or \n",
      "signature—and track their \n",
      "status every step of the way. \n",
      "Share files fast. Click, type, and \n",
      "send. It’s that easy. \n",
      "Collaborate better. Subscribers \n",
      "can also send files for e-signature or for review to collect \n",
      "group feedback in a single shared file. \n",
      "Manage your files. You’re in control. Track your file, \n",
      "forward it to others, or stop sharing it at any time.\n",
      "\n",
      "Page 3: 03 Present perfect content \n",
      "Combine and organize files \n",
      " \n",
      "Share materials exactly how you want—quickly and \n",
      "easily. \n",
      "Merge multiple files into \n",
      "one PDF. Combine different \n",
      "file types—spreadsheets, \n",
      "images, web pages, and \n",
      "videos—into a single PDF \n",
      "file that’s easy to share or \n",
      "archive. You can even add \n",
      "an entire folder. \n",
      "Organize pages. Rotate, \n",
      "delete, reorder, or insert pages in your PDF on your \n",
      "desktop, tablet, or mobile device.\n",
      "\n",
      "Page 5: 05 Get help from Adobe \n",
      "We’ve got your back \n",
      "Take advantage of tutorials \n",
      "and forums—and share your \n",
      "feedback with the Acrobat \n",
      "team. \n",
      "Get tutorials. Become an expert \n",
      "with short videos and online \n",
      "instruction. \n",
      "Visit Adobe Community. Ask questions and find answers \n",
      "in Acrobat forums. \n",
      "Share your feedback. We need your help to continue to \n",
      "make Acrobat the best solution available. Ple\n",
      "ase share your \n",
      "thoughts.\n",
      "\n",
      "Page 0: Welcome to  \n",
      "Adobe Acrobat \n",
      "Here are five tips to get real work  \n",
      "done from anywhere with Acrobat.  \n",
      "01 Work where you want \n",
      "02 Meet Acrobat AI Assistant \n",
      "03 Present perfect content \n",
      "04 Share files with others \n",
      "05 Get help from Adobe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "vector_store = InMemoryVectorStore.from_documents(\n",
    "    pages, OpenAIEmbeddings(model=\"text-embedding-3-small\"))\n",
    "docs = vector_store.similarity_search(\"tell me about share files with others\")\n",
    "\n",
    "for doc in docs:\n",
    "    print(f'Page {doc.metadata[\"page\"]}: {doc.page_content}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ad429a",
   "metadata": {},
   "source": [
    "### Layout analysis and extraction of text from images\n",
    "\n",
    "- If you want more control over the text extraction such as (extracting text from image, titles, tables other structure).\n",
    "- The following methods are good for these requires.\n",
    "- It will returns a list of document objects each object will represent a structure on the page.\n",
    "- The document meta data store page numbers and other information related to the objects.\n",
    "- It use **`langchain_structured`** library. see from [here](https://python.langchain.com/docs/integrations/document_loaders/unstructured_file/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a12b2057",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Preparing to split document for partition.\n",
      "INFO: Starting page number set to 1\n",
      "INFO: Allow failed set to 0\n",
      "INFO: Concurrency level set to 5\n",
      "INFO: Splitting pages 1 to 6 (6 total)\n",
      "INFO: Determined optimal split size of 2 pages.\n",
      "INFO: Partitioning 3 files with 2 page(s) each.\n",
      "INFO: Partitioning set #1 (pages 1-2).\n",
      "INFO: Partitioning set #2 (pages 3-4).\n",
      "INFO: Partitioning set #3 (pages 5-6).\n",
      "INFO: HTTP Request: POST https://api.unstructuredapp.io/general/v0/general \"HTTP/1.1 401 Unauthorized\"\n",
      "WARNING: Failed to partition set #1, its elements will be omitted in the final result.\n"
     ]
    },
    {
     "ename": "ServerError",
     "evalue": "{\"detail\":\"API key is missing, please provide an API key in the header.\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mServerError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     10\u001b[39m loader = UnstructuredLoader(\n\u001b[32m     11\u001b[39m     file_path=\u001b[33m\"\u001b[39m\u001b[33msample_files/welcome.pdf\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m     strategy=\u001b[33m\"\u001b[39m\u001b[33mhi_res\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m     partition_via_api=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     14\u001b[39m     coordinates=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     15\u001b[39m )\n\u001b[32m     16\u001b[39m docs = []\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Code\\Python\\Generative AI\\myenv\\Lib\\site-packages\\langchain_unstructured\\document_loaders.py:178\u001b[39m, in \u001b[36mUnstructuredLoader.lazy_load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    175\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    177\u001b[39m \u001b[38;5;66;03m# Call _UnstructuredBaseLoader normally since file and file_path are not lists\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m load_file(f=\u001b[38;5;28mself\u001b[39m.file, f_path=\u001b[38;5;28mself\u001b[39m.file_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Code\\Python\\Generative AI\\myenv\\Lib\\site-packages\\langchain_unstructured\\document_loaders.py:212\u001b[39m, in \u001b[36m_SingleDocumentLoader.lazy_load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlazy_load\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Iterator[Document]:\n\u001b[32m    208\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load file.\"\"\"\u001b[39;00m\n\u001b[32m    209\u001b[39m     elements_json = (\n\u001b[32m    210\u001b[39m         \u001b[38;5;28mself\u001b[39m._post_process_elements_json(\u001b[38;5;28mself\u001b[39m._elements_json)\n\u001b[32m    211\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.post_processors\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_elements_json\u001b[49m\n\u001b[32m    213\u001b[39m     )\n\u001b[32m    214\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m elements_json:\n\u001b[32m    215\u001b[39m         metadata = \u001b[38;5;28mself\u001b[39m._get_metadata()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Code\\Python\\Generative AI\\myenv\\Lib\\site-packages\\langchain_unstructured\\document_loaders.py:229\u001b[39m, in \u001b[36m_SingleDocumentLoader._elements_json\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Get elements as a list of dictionaries from local partition or via API.\"\"\"\u001b[39;00m\n\u001b[32m    228\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.partition_via_api:\n\u001b[32m--> \u001b[39m\u001b[32m229\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_elements_via_api\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._convert_elements_to_dicts(\u001b[38;5;28mself\u001b[39m._elements_via_local)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Code\\Python\\Generative AI\\myenv\\Lib\\site-packages\\langchain_unstructured\\document_loaders.py:258\u001b[39m, in \u001b[36m_SingleDocumentLoader._elements_via_api\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    256\u001b[39m client = \u001b[38;5;28mself\u001b[39m.client\n\u001b[32m    257\u001b[39m req = \u001b[38;5;28mself\u001b[39m._sdk_partition_request\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgeneral\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpartition\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code == \u001b[32m200\u001b[39m:\n\u001b[32m    260\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m json.loads(response.raw_response.text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Code\\Python\\Generative AI\\myenv\\Lib\\site-packages\\unstructured_client\\general.py:107\u001b[39m, in \u001b[36mGeneral.partition\u001b[39m\u001b[34m(self, request, retries)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m utils.match_content_type(http_res.headers.get(\u001b[33m'\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m'\u001b[39m):                \n\u001b[32m    106\u001b[39m     out = utils.unmarshal_json(http_res.text, errors.ServerError)\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m out\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    109\u001b[39m     content_type = http_res.headers.get(\u001b[33m'\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mServerError\u001b[39m: {\"detail\":\"API key is missing, please provide an API key in the header.\"}"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_unstructured import UnstructuredLoader\n",
    "\n",
    "if \"UNSTRUCTURED_API_KEY\" not in os.environ:\n",
    "    os.environ[\"UNSTRUCTURED_API_KEY\"] = getpass.getpass(\n",
    "        \"Unstructured API Key:\")\n",
    "\n",
    "\n",
    "loader = UnstructuredLoader(\n",
    "    file_path=\"sample_files/welcome.pdf\",\n",
    "    strategy=\"hi_res\",\n",
    "    partition_via_api=True,\n",
    "    coordinates=True,\n",
    ")\n",
    "docs = []\n",
    "for doc in loader.lazy_load():\n",
    "    docs.append(doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
