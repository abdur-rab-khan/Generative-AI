{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f9f5cf1",
   "metadata": {},
   "source": [
    "# ⚒️ Tool calling via chat model (OpenAI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca1b037",
   "metadata": {},
   "source": [
    "- Table of contents\n",
    "  - [Tool calling via chat model](#️-tool-calling-via-chat-model-openai)\n",
    "  - [Tool output to Chat Mode](#️-pass-tool-output-to-chat-models)\n",
    "  - [Pass Tool value in run time](#how-to-pass-run-time-value-to-the-tool)\n",
    "  - [How to stream tool calls](#how-to-stream-tool-calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab1fbf0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffbebc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "class InputSchema(BaseModel):\n",
    "    a: int = Field(description=\"first number\")\n",
    "    b: int = Field(description=\"second number\")\n",
    "\n",
    "\n",
    "@tool(args_schema=InputSchema)\n",
    "def multiply(a: int, b: int):\n",
    "    \"\"\"Multiply two numbers\"\"\"\n",
    "\n",
    "    return a * b\n",
    "\n",
    "\n",
    "@tool(args_schema=InputSchema)\n",
    "def add(a: int, b: int):\n",
    "    \"\"\"Add two numbers\"\"\"\n",
    "\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d440f9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'multiply': StructuredTool(name='multiply', description='Multiply two numbers', args_schema=<class '__main__.InputSchema'>, func=<function multiply at 0x00000200C75E99E0>), 'add': StructuredTool(name='add', description='Add two numbers', args_schema=<class '__main__.InputSchema'>, func=<function add at 0x00000200C75E9F80>)}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "tools = [multiply, add]\n",
    "tool_by_name = {tool.name: tool for tool in tools}\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f60813f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'multiply', 'args': {'a': 2, 'b': 5}, 'id': 'call_2FRwjIPOQSZbB5y9JIWsERWp', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 5, 'b': 5}, 'id': 'call_UTla1eAWzA383cldj47biA4z', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "query = \"what is 2 multiply by 5. then add by 5\"\n",
    "\n",
    "print(llm_with_tools.invoke(query).tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d18ff60",
   "metadata": {},
   "source": [
    "## ⚒️ Pass tool output to chat models\n",
    "\n",
    "![pass-tool-output-to-chat-models](https://python.langchain.com/assets/images/tool_invocation-7f277888701ee431a17607f1a035c080.png)\n",
    "\n",
    "![pass-tool-output-to-chat-models](https://python.langchain.com/assets/images/tool_results-71b4b90f33a56563c102d91e7821a993.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0e982fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_n7dPtZmrw7IsD0aShBwKRhRH', 'function': {'arguments': '{\"a\": 3, \"b\": 2}', 'name': 'multiply'}, 'type': 'function'}, {'id': 'call_WtoOMhOAwKdvfga0jMFeyncd', 'function': {'arguments': '{\"a\": 11, \"b\": 49}', 'name': 'add'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 96, 'total_tokens': 147, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_129a36352a', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-37d38044-dda7-44af-8362-1da3fabf2fd7-0' tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 2}, 'id': 'call_n7dPtZmrw7IsD0aShBwKRhRH', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': 'call_WtoOMhOAwKdvfga0jMFeyncd', 'type': 'tool_call'}] usage_metadata={'input_tokens': 96, 'output_tokens': 51, 'total_tokens': 147, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "query = \"what is 3 * 2? Also, what is 11 + 49\"\n",
    "\n",
    "messages = [HumanMessage(content=query)]\n",
    "\n",
    "ai_message = llm_with_tools.invoke(messages)\n",
    "\n",
    "print(ai_message)\n",
    "\n",
    "messages.append(ai_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eaaaa450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='what is 3 * 2? Also, what is 11 + 49', additional_kwargs={}, response_metadata={}), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_n7dPtZmrw7IsD0aShBwKRhRH', 'function': {'arguments': '{\"a\": 3, \"b\": 2}', 'name': 'multiply'}, 'type': 'function'}, {'id': 'call_WtoOMhOAwKdvfga0jMFeyncd', 'function': {'arguments': '{\"a\": 11, \"b\": 49}', 'name': 'add'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 96, 'total_tokens': 147, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_129a36352a', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-37d38044-dda7-44af-8362-1da3fabf2fd7-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 2}, 'id': 'call_n7dPtZmrw7IsD0aShBwKRhRH', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': 'call_WtoOMhOAwKdvfga0jMFeyncd', 'type': 'tool_call'}], usage_metadata={'input_tokens': 96, 'output_tokens': 51, 'total_tokens': 147, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='6', name='multiply', tool_call_id='call_n7dPtZmrw7IsD0aShBwKRhRH'), ToolMessage(content='60', name='add', tool_call_id='call_WtoOMhOAwKdvfga0jMFeyncd')]\n"
     ]
    }
   ],
   "source": [
    "for tool_call in ai_message.tool_calls:\n",
    "    select_tool = tool_by_name[tool_call[\"name\"]]\n",
    "    tool_msg = select_tool.invoke(tool_call)\n",
    "\n",
    "    messages.append(tool_msg)\n",
    "\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33a2f305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The result of \\\\(3 \\\\times 2\\\\) is \\\\(6\\\\), and \\\\(11 + 49\\\\) equals \\\\(60\\\\).', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 162, 'total_tokens': 193, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_129a36352a', 'finish_reason': 'stop', 'logprobs': None}, id='run-831e1509-dc9b-4ebf-bfaf-f9d825281c2c-0', usage_metadata={'input_tokens': 162, 'output_tokens': 31, 'total_tokens': 193, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e160ed3",
   "metadata": {},
   "source": [
    "## How to pass run time value to the tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f808bd0b",
   "metadata": {},
   "source": [
    "- You may need to bind value to a tool that are only know at runtime.\n",
    "- The tool may required the user id who invoke the tool.\n",
    "- We can't pass the tool to LLM's for security risk instead of LLM's may control parameters.\n",
    "- We pass the `user_id` during invoke of the tool by using `InjectedToolArg` annotation.\n",
    "- `InjectedToolArg` is used to mark annotation on some parameters, `user_id` as begin injected at runtime meaning they should not being generated by the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ff9b87d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool, InjectedToolArg\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "de21da21",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_pets = {}\n",
    "\n",
    "\n",
    "@tool(parse_docstring=True)\n",
    "def update_favorite_pet(pets: List[str], user_id: Annotated[str, InjectedToolArg]) -> None:\n",
    "    \"\"\"\n",
    "    Add the list of favorite pets.\n",
    "\n",
    "    Args:\n",
    "        pets: The list of favorite pets to set.\n",
    "        user_id: User's Id\n",
    "    \"\"\"\n",
    "    user_to_pets[user_id] = pets\n",
    "\n",
    "\n",
    "@tool(parse_docstring=True)\n",
    "def delete_favorite_pet(user_id: Annotated[str, InjectedToolArg]) -> None:\n",
    "    \"\"\"\n",
    "    Delete the list of favorite pets\n",
    "\n",
    "    Args:\n",
    "        user_id: User's Id\n",
    "    \"\"\"\n",
    "    if user_id in user_to_pets:\n",
    "        del user_to_pets[user_id]\n",
    "\n",
    "\n",
    "@tool(parse_docstring=True)\n",
    "def list_favorite_pet(user_id: Annotated[str, InjectedToolArg]) -> None:\n",
    "    \"\"\"\n",
    "    List favorite pets of any.\n",
    "\n",
    "    Args:\n",
    "        user_id: User's Id\n",
    "    \"\"\"\n",
    "    return user_to_pets.get(user_id, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e84dd5",
   "metadata": {},
   "source": [
    "- If we look input schemas for these tool, we'll see that `user_id` is still listed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75779fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Add the list of favorite pets.',\n",
       " 'properties': {'pets': {'description': 'The list of favorite pets to set.',\n",
       "   'items': {'type': 'string'},\n",
       "   'title': 'Pets',\n",
       "   'type': 'array'},\n",
       "  'user_id': {'description': \"User's Id\",\n",
       "   'title': 'User Id',\n",
       "   'type': 'string'}},\n",
       " 'required': ['pets', 'user_id'],\n",
       " 'title': 'update_favorite_pet',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_favorite_pet.get_input_schema().model_json_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab33e45a",
   "metadata": {},
   "source": [
    "- If we look at that passed into the model, we see there is not `user_id`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72901835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Add the list of favorite pets.',\n",
       " 'properties': {'pets': {'description': 'The list of favorite pets to set.',\n",
       "   'items': {'type': 'string'},\n",
       "   'title': 'Pets',\n",
       "   'type': 'array'}},\n",
       " 'required': ['pets'],\n",
       " 'title': 'update_favorite_pet',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_favorite_pet.tool_call_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d9d719",
   "metadata": {},
   "source": [
    "- So let's invoke our tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7e329ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pandas', 'koala']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = \"123\"\n",
    "\n",
    "update_favorite_pet.invoke(\n",
    "    {\n",
    "        \"pets\": [\"pandas\", \"koala\"],\n",
    "        \"user_id\": user_id\n",
    "    }\n",
    ")\n",
    "\n",
    "list_favorite_pet.invoke({\"user_id\": user_id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "15c28f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    update_favorite_pet,\n",
    "    delete_favorite_pet,\n",
    "    list_favorite_pet\n",
    "]\n",
    "\n",
    "tool_by_name = {tool.name: tool for tool in tools}\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c8941b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'update_favorite_pet',\n",
       "  'args': {'pets': ['cats', 'parrots']},\n",
       "  'id': 'call_yuyLzfrAWY5n9g2wJRzssJt4',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg = llm_with_tools.invoke(\"my favorite animals are cats and parrots\")\n",
    "ai_msg.tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7dabf36",
   "metadata": {},
   "source": [
    "- See there is not `user_id` field in the tool call, this is because of `InjectToolCall`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab123953",
   "metadata": {},
   "source": [
    "- If we want to actually execute our tool using the model-generator we'll need to manually inject the `user_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4654011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from langchain_core.runnables import chain\n",
    "\n",
    "\n",
    "@chain\n",
    "def injected_user_id(ai_msg):\n",
    "    tool_calls = []\n",
    "    for tool_call in ai_msg.tool_calls:\n",
    "        tool_call_copy = deepcopy(tool_call)\n",
    "        tool_call_copy[\"args\"][\"user_id\"] = user_id\n",
    "        tool_calls.append(tool_call_copy)\n",
    "\n",
    "    return tool_calls\n",
    "\n",
    "\n",
    "injected_user_id.invoke(ai_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "5cb5b37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@chain\n",
    "def tool_router(tool_call):\n",
    "    return tool_by_name[tool_call[\"name\"]]\n",
    "\n",
    "\n",
    "chain = llm_with_tools | injected_user_id | tool_router.map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2c9064bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ToolMessage(content='null', name='update_favorite_pet', tool_call_id='call_4Yms1sD6Ahq0H0e5yDz5GDKw')]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"my favorite animals are pandas, parrots, koalas, cats, dogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "527fc61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'123': ['pandas', 'parrots', 'koalas', 'cats', 'dogs']}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_to_pets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8e4812",
   "metadata": {},
   "source": [
    "## How to stream tool calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b179e880",
   "metadata": {},
   "source": [
    "- When tool are called in a streaming way, the message chunks will be populate with the tool call chunk object in a list via a the .tool_call_chunks attributes.\n",
    "- A `ToolCallChunks` includes optional string fields such as `id`, `name`, `args` and includes an optional integer field index that can be used to join chunks together.\n",
    "- Fields are optional because portions of a tool call may be streamed across different chunks.\n",
    "- An AIMessageChunk with tool call chunks will also include .tool_calls and .invalid_tool_calls fields. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad8af2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int):\n",
    "    \"\"\"Add two numbers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int):\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "tools = [add, multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55fc6c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "922920c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[{'name': 'multiply', 'args': '', 'id': 'call_1vz0ngvV2B8Qun3sp2fer2VP', 'index': 0, 'type': 'tool_call_chunk'}]\n",
      "[{'name': None, 'args': '{\"a\"', 'id': None, 'index': 0, 'type': 'tool_call_chunk'}]\n",
      "[{'name': None, 'args': ': 3, ', 'id': None, 'index': 0, 'type': 'tool_call_chunk'}]\n",
      "[{'name': None, 'args': '\"b\": 1', 'id': None, 'index': 0, 'type': 'tool_call_chunk'}]\n",
      "[{'name': None, 'args': '2}', 'id': None, 'index': 0, 'type': 'tool_call_chunk'}]\n",
      "[{'name': 'add', 'args': '', 'id': 'call_5kuRsyqAgBtsBUnXYsHemqjP', 'index': 1, 'type': 'tool_call_chunk'}]\n",
      "[{'name': None, 'args': '{\"a\"', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]\n",
      "[{'name': None, 'args': ': 12,', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]\n",
      "[{'name': None, 'args': ' \"b\": ', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]\n",
      "[{'name': None, 'args': '12}', 'id': None, 'index': 1, 'type': 'tool_call_chunk'}]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "query = \"what is 3 * 12, Also, what is 12 + 12\"\n",
    "\n",
    "async for chunk in llm_with_tools.astream(query):\n",
    "    print(chunk.tool_call_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854f59b7",
   "metadata": {},
   "source": [
    "- The given message chunks will be merge their corresponding tool call chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbb4e4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={} response_metadata={} id='run-4b64d5ad-5951-4fe8-8fee-9aa6f04006d0'\n",
      "content='' additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'function': {'arguments': '', 'name': 'multiply'}, 'type': 'function'}]} response_metadata={} id='run-4b64d5ad-5951-4fe8-8fee-9aa6f04006d0' tool_calls=[{'name': 'multiply', 'args': {}, 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'type': 'tool_call'}] tool_call_chunks=[{'name': 'multiply', 'args': '', 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'index': 0, 'type': 'tool_call_chunk'}]\n",
      "content='' additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'function': {'arguments': '{\"a\"', 'name': 'multiply'}, 'type': 'function'}]} response_metadata={} id='run-4b64d5ad-5951-4fe8-8fee-9aa6f04006d0' tool_calls=[{'name': 'multiply', 'args': {}, 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'type': 'tool_call'}] tool_call_chunks=[{'name': 'multiply', 'args': '{\"a\"', 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'index': 0, 'type': 'tool_call_chunk'}]\n",
      "content='' additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'function': {'arguments': '{\"a\": 3, ', 'name': 'multiply'}, 'type': 'function'}]} response_metadata={} id='run-4b64d5ad-5951-4fe8-8fee-9aa6f04006d0' tool_calls=[{'name': 'multiply', 'args': {'a': 3}, 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'type': 'tool_call'}] tool_call_chunks=[{'name': 'multiply', 'args': '{\"a\": 3, ', 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'index': 0, 'type': 'tool_call_chunk'}]\n",
      "content='' additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'function': {'arguments': '{\"a\": 3, \"b\": 1', 'name': 'multiply'}, 'type': 'function'}]} response_metadata={} id='run-4b64d5ad-5951-4fe8-8fee-9aa6f04006d0' tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 1}, 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'type': 'tool_call'}] tool_call_chunks=[{'name': 'multiply', 'args': '{\"a\": 3, \"b\": 1', 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'index': 0, 'type': 'tool_call_chunk'}]\n",
      "content='' additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'function': {'arguments': '{\"a\": 3, \"b\": 12}', 'name': 'multiply'}, 'type': 'function'}]} response_metadata={} id='run-4b64d5ad-5951-4fe8-8fee-9aa6f04006d0' tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'type': 'tool_call'}] tool_call_chunks=[{'name': 'multiply', 'args': '{\"a\": 3, \"b\": 12}', 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'index': 0, 'type': 'tool_call_chunk'}]\n",
      "content='' additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'function': {'arguments': '{\"a\": 3, \"b\": 12}', 'name': 'multiply'}, 'type': 'function'}, {'index': 1, 'id': 'call_mthl0E4zZUO4hfarfsooj9HB', 'function': {'arguments': '', 'name': 'add'}, 'type': 'function'}]} response_metadata={} id='run-4b64d5ad-5951-4fe8-8fee-9aa6f04006d0' tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'type': 'tool_call'}, {'name': 'add', 'args': {}, 'id': 'call_mthl0E4zZUO4hfarfsooj9HB', 'type': 'tool_call'}] tool_call_chunks=[{'name': 'multiply', 'args': '{\"a\": 3, \"b\": 12}', 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'index': 0, 'type': 'tool_call_chunk'}, {'name': 'add', 'args': '', 'id': 'call_mthl0E4zZUO4hfarfsooj9HB', 'index': 1, 'type': 'tool_call_chunk'}]\n",
      "content='' additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'function': {'arguments': '{\"a\": 3, \"b\": 12}', 'name': 'multiply'}, 'type': 'function'}, {'index': 1, 'id': 'call_mthl0E4zZUO4hfarfsooj9HB', 'function': {'arguments': '{\"a\"', 'name': 'add'}, 'type': 'function'}]} response_metadata={} id='run-4b64d5ad-5951-4fe8-8fee-9aa6f04006d0' tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'type': 'tool_call'}, {'name': 'add', 'args': {}, 'id': 'call_mthl0E4zZUO4hfarfsooj9HB', 'type': 'tool_call'}] tool_call_chunks=[{'name': 'multiply', 'args': '{\"a\": 3, \"b\": 12}', 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'index': 0, 'type': 'tool_call_chunk'}, {'name': 'add', 'args': '{\"a\"', 'id': 'call_mthl0E4zZUO4hfarfsooj9HB', 'index': 1, 'type': 'tool_call_chunk'}]\n",
      "content='' additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'function': {'arguments': '{\"a\": 3, \"b\": 12}', 'name': 'multiply'}, 'type': 'function'}, {'index': 1, 'id': 'call_mthl0E4zZUO4hfarfsooj9HB', 'function': {'arguments': '{\"a\": 12,', 'name': 'add'}, 'type': 'function'}]} response_metadata={} id='run-4b64d5ad-5951-4fe8-8fee-9aa6f04006d0' tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 12}, 'id': 'call_mthl0E4zZUO4hfarfsooj9HB', 'type': 'tool_call'}] tool_call_chunks=[{'name': 'multiply', 'args': '{\"a\": 3, \"b\": 12}', 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'index': 0, 'type': 'tool_call_chunk'}, {'name': 'add', 'args': '{\"a\": 12,', 'id': 'call_mthl0E4zZUO4hfarfsooj9HB', 'index': 1, 'type': 'tool_call_chunk'}]\n",
      "content='' additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'function': {'arguments': '{\"a\": 3, \"b\": 12}', 'name': 'multiply'}, 'type': 'function'}, {'index': 1, 'id': 'call_mthl0E4zZUO4hfarfsooj9HB', 'function': {'arguments': '{\"a\": 12, \"b\": ', 'name': 'add'}, 'type': 'function'}]} response_metadata={} id='run-4b64d5ad-5951-4fe8-8fee-9aa6f04006d0' tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 12}, 'id': 'call_mthl0E4zZUO4hfarfsooj9HB', 'type': 'tool_call'}] tool_call_chunks=[{'name': 'multiply', 'args': '{\"a\": 3, \"b\": 12}', 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'index': 0, 'type': 'tool_call_chunk'}, {'name': 'add', 'args': '{\"a\": 12, \"b\": ', 'id': 'call_mthl0E4zZUO4hfarfsooj9HB', 'index': 1, 'type': 'tool_call_chunk'}]\n",
      "content='' additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'function': {'arguments': '{\"a\": 3, \"b\": 12}', 'name': 'multiply'}, 'type': 'function'}, {'index': 1, 'id': 'call_mthl0E4zZUO4hfarfsooj9HB', 'function': {'arguments': '{\"a\": 12, \"b\": 12}', 'name': 'add'}, 'type': 'function'}]} response_metadata={} id='run-4b64d5ad-5951-4fe8-8fee-9aa6f04006d0' tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 12, 'b': 12}, 'id': 'call_mthl0E4zZUO4hfarfsooj9HB', 'type': 'tool_call'}] tool_call_chunks=[{'name': 'multiply', 'args': '{\"a\": 3, \"b\": 12}', 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'index': 0, 'type': 'tool_call_chunk'}, {'name': 'add', 'args': '{\"a\": 12, \"b\": 12}', 'id': 'call_mthl0E4zZUO4hfarfsooj9HB', 'index': 1, 'type': 'tool_call_chunk'}]\n",
      "content='' additional_kwargs={'tool_calls': [{'index': 0, 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'function': {'arguments': '{\"a\": 3, \"b\": 12}', 'name': 'multiply'}, 'type': 'function'}, {'index': 1, 'id': 'call_mthl0E4zZUO4hfarfsooj9HB', 'function': {'arguments': '{\"a\": 12, \"b\": 12}', 'name': 'add'}, 'type': 'function'}]} response_metadata={'finish_reason': 'tool_calls', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0392822090'} id='run-4b64d5ad-5951-4fe8-8fee-9aa6f04006d0' tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 12, 'b': 12}, 'id': 'call_mthl0E4zZUO4hfarfsooj9HB', 'type': 'tool_call'}] tool_call_chunks=[{'name': 'multiply', 'args': '{\"a\": 3, \"b\": 12}', 'id': 'call_BRODoggbnSBckl8lwwEGUReF', 'index': 0, 'type': 'tool_call_chunk'}, {'name': 'add', 'args': '{\"a\": 12, \"b\": 12}', 'id': 'call_mthl0E4zZUO4hfarfsooj9HB', 'index': 1, 'type': 'tool_call_chunk'}]\n"
     ]
    }
   ],
   "source": [
    "first = True\n",
    "\n",
    "async for chunk in llm_with_tools.astream(query):\n",
    "    if first:\n",
    "        gathered = chunk\n",
    "        first = False\n",
    "    else:\n",
    "        gathered = gathered + chunk\n",
    "\n",
    "    print(gathered)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
